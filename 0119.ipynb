{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essentials\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "\n",
    "#Models\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "import xgboost\n",
    "import lightgbm\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "# from mlxtend.regressor import StackingCVRegressor\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "#Misc\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# path = 'C:\\\\Users\\\\sunsharp\\\\Desktop\\\\kaggle\\\\data-science-bowl-2019\\\\'\n",
    "path='/Users/ranmo/Desktop/kaggle/data-science bowl/'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data\\\\train.csv')\n",
    "train_labels = pd.read_csv('data\\\\train_labels.csv')\n",
    "specs=pd.read_csv('data\\\\specs.csv')\n",
    "test = pd.read_csv('data\\\\test.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train data (11341042, 11)\n",
      "Size of train_labels data (17690, 7)\n",
      "Size of specs data (386, 3)\n",
      "Size of test data (1156414, 11)\n"
     ]
    }
   ],
   "source": [
    "print('Size of train data', train.shape)\n",
    "print('Size of train_labels data', train_labels.shape)\n",
    "print('Size of specs data', specs.shape)\n",
    "print('Size of test data', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to reduce the DF size\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 778.73 Mb (18.2% reduction)\n",
      "Mem. usage decreased to  0.49 Mb (48.2% reduction)\n",
      "Mem. usage decreased to  0.01 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 79.40 Mb (18.2% reduction)\n"
     ]
    }
   ],
   "source": [
    "## Reducing memory\n",
    "train = reduce_mem_usage(train)\n",
    "train_labels = reduce_mem_usage(train_labels)\n",
    "specs = reduce_mem_usage(specs)\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11341042 entries, 0 to 11341041\n",
      "Data columns (total 11 columns):\n",
      "event_id           object\n",
      "game_session       object\n",
      "timestamp          object\n",
      "event_data         object\n",
      "installation_id    object\n",
      "event_count        int16\n",
      "event_code         int16\n",
      "game_time          int32\n",
      "title              object\n",
      "type               object\n",
      "world              object\n",
      "dtypes: int16(2), int32(1), object(8)\n",
      "memory usage: 778.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17690 entries, 0 to 17689\n",
      "Data columns (total 7 columns):\n",
      "game_session       17690 non-null object\n",
      "installation_id    17690 non-null object\n",
      "title              17690 non-null object\n",
      "num_correct        17690 non-null int8\n",
      "num_incorrect      17690 non-null int8\n",
      "accuracy           17690 non-null float16\n",
      "accuracy_group     17690 non-null int8\n",
      "dtypes: float16(1), int8(3), object(3)\n",
      "memory usage: 501.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 386 entries, 0 to 385\n",
      "Data columns (total 3 columns):\n",
      "event_id    386 non-null object\n",
      "info        386 non-null object\n",
      "args        386 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 9.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1156414 entries, 0 to 1156413\n",
      "Data columns (total 11 columns):\n",
      "event_id           1156414 non-null object\n",
      "game_session       1156414 non-null object\n",
      "timestamp          1156414 non-null object\n",
      "event_data         1156414 non-null object\n",
      "installation_id    1156414 non-null object\n",
      "event_count        1156414 non-null int16\n",
      "event_code         1156414 non-null int16\n",
      "game_time          1156414 non-null int32\n",
      "title              1156414 non-null object\n",
      "type               1156414 non-null object\n",
      "world              1156414 non-null object\n",
      "dtypes: int16(2), int32(1), object(8)\n",
      "memory usage: 79.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.info())\n",
    "display(train_labels.info())\n",
    "display(specs.info())\n",
    "display(test.info())\n",
    "\n",
    "train.to_csv('data\\\\new\\\\train.csv',index=False)\n",
    "train_labels.to_csv('data\\\\new\\\\train_labels.csv',index=False)\n",
    "specs.to_csv('data\\\\new\\\\specs.csv',index=False)\n",
    "test.to_csv('data\\\\new\\\\test.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv('data\\\\new\\\\train.csv')\n",
    "# train_labels = pd.read_csv('data\\\\new\\\\train_labels.csv')\n",
    "# specs=pd.read_csv('data\\\\new\\\\specs.csv')\n",
    "# test = pd.read_csv('data\\\\new\\\\test.csv') \n",
    "# sample_submission=pd.read_csv('data\\\\sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实际上后面train是train_new\n",
    "train_new=train.copy()\n",
    "train_labels_new=train_labels.copy()\n",
    "specs_new=specs.copy()\n",
    "test_new=test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**原始数据中存在非数值型数据，需要对其转换：**\n",
    "- event_id：表示不同的事件类型，类似于点击、滑屏等操作属性，所以不同程序也会有同样的event_id；\n",
    "- game_session：程序编号，具备唯一性，一个程序可以有多个event_id，即多个操作；\n",
    "- timestamp：需要转换为时间戳数据；\n",
    "- installation_id：主机编号，具备唯一性\n",
    "- event_data：包含event_count和event_code，所以只用对event_count和event_code操作就可以；\n",
    "- event_count：对event_id的计数，理应都是从1开始计数的，但是里面部分数据并不是从1开始计数；\n",
    "- event_code：表示事件类型所属的类，所以又多个event_id会归属于一类event_code，例如单击和双击会有同样的event_code（只是举个例子）；\n",
    "- game_time：event发生后的持续事件；\n",
    "- title：程序的名称，有数十种；\n",
    "- type：程序的类型，有四种： 'Game', 'Assessment', 'Activity', 'Clip'（开场动画）；\n",
    "- world：程序的内容，有四种：'NONE' (at the app's start screen), TREETOPCITY' (长/高), 'MAGMAPEAK' (容量/距离), 'CRYSTALCAVES' (重量)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**生成几个dict来映射原数据，分别是 :**\n",
    "- win_code:不同的程序（title）进行评估的event_code，如果某次评估正确的话，在对应的evetn_code会包含有\"correct\":true的字样。可参见 train_new[train_new.event_code==4110]\n",
    "- list_of_user_activities：不同的程序（title）的总列表\n",
    "- list_of_event_code:不同的event_code的总列表\n",
    "- activities_labels：list_of_user_activities所形成的字典\n",
    "- assess_titles：程序类型的总列表\n",
    "- list_of_event_id：不同事件类型形成的总列表\n",
    "- all_title_event_code:由不同的程序+event_code形成的总列表，表示的是有的程序的话是并不会具备所有code的，比如游戏类型可能就不会有人进行最大最小化操作\n",
    "\n",
    "**返回编码后的数据集：**\n",
    "- train&test:编码的字段包括timestamp、title、world，此外新增了两个字段title_event_code和hour（提取时间戳中的小时）\n",
    "- train_labels:编码字段包括title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encode_title(train, test, train_labels):\n",
    "    # encode title\n",
    "    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n",
    "    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n",
    "    all_title_event_code = list(set(train[\"title_event_code\"].unique()).union(test[\"title_event_code\"].unique()))\n",
    "    # make a list with all the unique 'titles' from the train and test set\n",
    "    list_of_user_activities = list(set(train['title'].unique()).union(set(test['title'].unique())))\n",
    "    # make a list with all the unique 'event_code' from the train and test set\n",
    "    list_of_event_code = list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))\n",
    "    list_of_event_id = list(set(train['event_id'].unique()).union(set(test['event_id'].unique())))\n",
    "    # make a list with all the unique worlds from the train and test set\n",
    "    list_of_worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n",
    "    # create a dictionary numerating the titles\n",
    "    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n",
    "    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n",
    "    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n",
    "    assess_titles = list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index)))\n",
    "    # replace the text titles with the number titles from the dict\n",
    "    train['title'] = train['title'].map(activities_map)\n",
    "    test['title'] = test['title'].map(activities_map)\n",
    "    train['world'] = train['world'].map(activities_world)\n",
    "    test['world'] = test['world'].map(activities_world)\n",
    "    train_labels['title'] = train_labels['title'].map(activities_map)\n",
    "    win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n",
    "    # then, it set one element, the 'Bird Measurer (Assessment)' as 4110, 10 more than the rest\n",
    "    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n",
    "    # convert text into datetime\n",
    "    train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "    test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "    # hour\n",
    "    train['hour'] = train['timestamp'].dt.hour\n",
    "    test['hour'] = test['timestamp'].dt.hour\n",
    "    \n",
    "    return train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**扩展特征维度，共计915个特征**\n",
    "- 四种类型的计数，len=4\n",
    "- 五种测试的准确度，len=5（不存在则为-1）\n",
    "- list_of_event_code，len=42\n",
    "- list_of_event_id，len=384\n",
    "- list_of_user_activities,len=44\n",
    "- all_title_event_code,len=403\n",
    "- installation_session_count,len=1\n",
    "- hour,len=1\n",
    "- 三种类型的平均event_count,len=3（clip通常都只是1条，所以这里不包含）\n",
    "- 关于game的特殊特征：mean_game_round，mean_game_duration，mean_game_level，accumulated_game_miss，len=4\n",
    "- event_code、event_id、title、title_event_code的零值（var）计数，len=4\n",
    "- installation_id和session_title，len=2\n",
    "- 以及其他的特征。。\n",
    "\n",
    "\n",
    "reduce_train.installation_id.value_counts()[reduce_train.installation_id.value_counts()==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clip的程序运行时长用平均时长来代替，其他类型 'Game', 'Assessment', 'Activity',的程序运行时长则计算得出。\n",
    "#（因为clip通常只有一个event，无法利用event的时间说相减来计算）\n",
    "clip_time = {'Welcome to Lost Lagoon!':19,'Tree Top City - Level 1':17,'Ordering Spheres':61, 'Costume Box':61,\n",
    "        '12 Monkeys':109,'Tree Top City - Level 2':25, 'Pirate\\'s Tale':80, 'Treasure Map':156,'Tree Top City - Level 3':26,\n",
    "        'Rulers':126, 'Magma Peak - Level 1':20, 'Slop Problem':60, 'Magma Peak - Level 2':22, 'Crystal Caves - Level 1':18,\n",
    "        'Balancing Act':72, 'Lifting Heavy Things':118,'Crystal Caves - Level 2':24, 'Honey Cake':142, 'Crystal Caves - Level 3':19,\n",
    "        'Heavy, Heavier, Heaviest':61}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 专门针对game的event_data，计算里面缺失项数目\n",
    "def cnt_miss(df):\n",
    "    cnt = 0\n",
    "    for e in range(len(df)):\n",
    "        x = df['event_data'].iloc[e]\n",
    "        y = json.loads(x)['misses']\n",
    "        cnt += y\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the function that convert the raw data into processed features\n",
    "def get_data(user_sample, test_set=False):\n",
    "    '''\n",
    "    The user_sample is a DataFrame from train or test where the only one \n",
    "    installation_id is filtered\n",
    "    And the test_set parameter is related with the labels processing, that is only requered\n",
    "    if test_set=False\n",
    "    '''\n",
    "    # Constants and parameters declaration\n",
    "    last_activity = 0\n",
    "    \n",
    "    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "    game_time_dict = {'Clip_gametime':0, 'Game_gametime':0, 'Activity_gametime':0, 'Assessment_gametime':0}\n",
    "    Assessment_mean_event_count = 0\n",
    "    Game_mean_event_count = 0\n",
    "    Activity_mean_event_count = 0\n",
    "    mean_game_round = 0\n",
    "    mean_game_duration = 0 \n",
    "    mean_game_level = 0\n",
    "    accumulated_game_miss = 0\n",
    "    \n",
    "    # new features: time spent in each activity\n",
    "    last_session_time_sec = 0\n",
    "    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n",
    "    all_assessments = []\n",
    "    accumulated_accuracy_group = 0\n",
    "    accumulated_accuracy = 0\n",
    "    accumulated_correct_attempts = 0 \n",
    "    accumulated_uncorrect_attempts = 0\n",
    "    accumulated_actions = 0\n",
    "    counter = 0\n",
    "    time_first_activity = float(user_sample['timestamp'].values[0])\n",
    "    durations = []\n",
    "    clip_durations = []\n",
    "    Activity_durations = []\n",
    "    Game_durations = []\n",
    "    \n",
    "    last_accuracy_title = {'acc_' + title: -1 for title in assess_titles}\n",
    "    event_code_count: Dict[str, int] = {ev: 0 for ev in list_of_event_code}\n",
    "    event_id_count: Dict[str, int] = {eve: 0 for eve in list_of_event_id}\n",
    "    title_count: Dict[str, int] = {eve: 0 for eve in activities_labels.values()} \n",
    "    title_event_code_count: Dict[str, int] = {t_eve: 0 for t_eve in all_title_event_code}\n",
    "        \n",
    "    # last features\n",
    "    sessions_count = 0\n",
    "    \n",
    "    # itarates through each session of one instalation_id\n",
    "    for i, session in user_sample.groupby('game_session', sort=False):\n",
    "        # i = game_session_id\n",
    "        # session is a DataFrame that contain only one game_session\n",
    "        \n",
    "        # get some sessions information\n",
    "        session_type = session['type'].iloc[0]\n",
    "        session_title = session['title'].iloc[0]\n",
    "        session_title_text = activities_labels[session_title]\n",
    "                    \n",
    "        if session_type == 'Clip':\n",
    "            clip_durations.append((clip_time[activities_labels[session_title]]))\n",
    "        \n",
    "        if session_type == 'Activity':\n",
    "            Activity_durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n",
    "            Activity_mean_event_count = (Activity_mean_event_count + session['event_count'].iloc[-1])/2.0\n",
    "        \n",
    "        if session_type == 'Game':\n",
    "            Game_durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n",
    "            Game_mean_event_count = (Game_mean_event_count + session['event_count'].iloc[-1])/2.0\n",
    "            \n",
    "            game_s = session[session.event_code == 2030]   \n",
    "            misses_cnt = cnt_miss(game_s)\n",
    "            accumulated_game_miss += misses_cnt\n",
    "            \n",
    "            try:\n",
    "                game_round = json.loads(session['event_data'].iloc[-1])[\"round\"]\n",
    "                mean_game_round =  (mean_game_round + game_round)/2.0\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                game_duration = json.loads(session['event_data'].iloc[-1])[\"duration\"]\n",
    "                mean_game_duration = (mean_game_duration + game_duration) /2.0\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                game_level = json.loads(session['event_data'].iloc[-1])[\"level\"]\n",
    "                mean_game_level = (mean_game_level + game_level) /2.0\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        # for each assessment, and only this kind off session, the features below are processed\n",
    "        # and a register are generated\n",
    "        if (session_type == 'Assessment') & (test_set or len(session)>1):\n",
    "            # search for event_code 4100, that represents the assessments trial\n",
    "            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n",
    "            # then, check the numbers of wins and the number of losses\n",
    "            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n",
    "            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n",
    "            # copy a dict to use as feature template, it's initialized with some itens: \n",
    "            # {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "            features = user_activities_count.copy()\n",
    "            features.update(last_accuracy_title.copy())\n",
    "            features.update(event_code_count.copy())\n",
    "            features.update(event_id_count.copy())\n",
    "            features.update(title_count.copy())\n",
    "            features.update(title_event_code_count.copy())\n",
    "            features.update(last_accuracy_title.copy())\n",
    "            # features.update(game_time_dict.copy())\n",
    "            \n",
    "            features['installation_session_count'] = sessions_count\n",
    "            features['hour'] = session['hour'].iloc[-1]\n",
    "            features['Assessment_mean_event_count'] = Assessment_mean_event_count\n",
    "            features['Game_mean_event_count'] = Game_mean_event_count\n",
    "            features['Activity_mean_event_count'] = Activity_mean_event_count\n",
    "            features['mean_game_round'] = mean_game_round\n",
    "            features['mean_game_duration'] = mean_game_duration\n",
    "            features['mean_game_level'] = mean_game_level\n",
    "            features['accumulated_game_miss'] = accumulated_game_miss\n",
    "            \n",
    "            variety_features = [('var_event_code', event_code_count),\n",
    "                              ('var_event_id', event_id_count),\n",
    "                               ('var_title', title_count),\n",
    "                               ('var_title_event_code', title_event_code_count)]\n",
    "            \n",
    "            for name, dict_counts in variety_features:\n",
    "                arr = np.array(list(dict_counts.values()))\n",
    "                features[name] = np.count_nonzero(arr)\n",
    "                 \n",
    "            # get installation_id for aggregated features\n",
    "            features['installation_id'] = session['installation_id'].iloc[-1]\n",
    "            # add title as feature, remembering that title represents the name of the game\n",
    "            features['session_title'] = session['title'].iloc[0]\n",
    "            # the 4 lines below add the feature of the history of the trials of this player\n",
    "            # this is based on the all time attempts so far, at the moment of this assessment\n",
    "            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n",
    "            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n",
    "            accumulated_correct_attempts += true_attempts \n",
    "            accumulated_uncorrect_attempts += false_attempts\n",
    "            # the time spent in the app so far\n",
    "            if durations == []:\n",
    "                features['duration_mean'] = 0\n",
    "                features['duration_std'] = 0\n",
    "            else:\n",
    "                features['duration_mean'] = np.mean(durations)\n",
    "                features['duration_std'] = np.std(durations)\n",
    "            if clip_durations == []:\n",
    "                features['Clip_duration_mean'] = 0\n",
    "                features['Clip_duration_std'] = 0\n",
    "            else:\n",
    "                features['Clip_duration_mean'] = np.mean(clip_durations)\n",
    "                features['Clip_duration_std'] = np.std(clip_durations)\n",
    "                \n",
    "            if Activity_durations == []:\n",
    "                features['Activity_duration_mean'] = 0\n",
    "                features['Activity_duration_std'] = 0\n",
    "            else:\n",
    "                features['Activity_duration_mean'] = np.mean(Activity_durations)\n",
    "                features['Activity_duration_std'] = np.std(Activity_durations)\n",
    "                \n",
    "            if Game_durations == []:\n",
    "                features['Game_duration_mean'] = 0\n",
    "                features['Game_duration_std'] = 0\n",
    "            else:\n",
    "                features['Game_duration_mean'] = np.mean(Game_durations)\n",
    "                features['Game_duration_std'] = np.std(Game_durations)\n",
    "            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n",
    "            Assessment_mean_event_count = (Assessment_mean_event_count + session['event_count'].iloc[-1])/2.0\n",
    "            # the accurace is the all time wins divided by the all time attempts\n",
    "            features['accumulated_accuracy'] = accumulated_accuracy/counter if counter > 0 else 0\n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "            accumulated_accuracy += accuracy\n",
    "            last_accuracy_title['acc_' + session_title_text] = accuracy\n",
    "            # a feature of the current accuracy categorized\n",
    "            # it is a counter of how many times this player was in each accuracy group\n",
    "            if accuracy == 0:\n",
    "                features['accuracy_group'] = 0\n",
    "            elif accuracy == 1:\n",
    "                features['accuracy_group'] = 3\n",
    "            elif accuracy == 0.5:\n",
    "                features['accuracy_group'] = 2\n",
    "            else:\n",
    "                features['accuracy_group'] = 1\n",
    "            features.update(accuracy_groups)\n",
    "            accuracy_groups[features['accuracy_group']] += 1\n",
    "            # mean of the all accuracy groups of this player\n",
    "            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n",
    "            accumulated_accuracy_group += features['accuracy_group']\n",
    "            # how many actions the player has done so far, it is initialized as 0 and updated some lines below\n",
    "            features['accumulated_actions'] = accumulated_actions\n",
    "            \n",
    "            # there are some conditions to allow this features to be inserted in the datasets\n",
    "            # if it's a test set, all sessions belong to the final dataset\n",
    "            # it it's a train, needs to be passed throught this clausule: session.query(f'event_code == {win_code[session_title]}')\n",
    "            # that means, must exist an event_code 4100 or 4110\n",
    "            if test_set:\n",
    "                all_assessments.append(features)\n",
    "            elif true_attempts+false_attempts > 0:\n",
    "                all_assessments.append(features)\n",
    "                \n",
    "            counter += 1\n",
    "    if test_set:\n",
    "        return all_assessments[-1]\n",
    "    # in the train_set, all assessments goes to the dataset\n",
    "    return all_assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**转换数据集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_test(train, test):\n",
    "    compiled_train = []\n",
    "    compiled_test = []\n",
    "    for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort = False)), total = 17000):\n",
    "        compiled_train += get_data(user_sample)\n",
    "    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort = False), total = 1000):\n",
    "        test_data = get_data(user_sample, test_set = True)\n",
    "        compiled_test.append(test_data)\n",
    "    reduce_train = pd.DataFrame(compiled_train)\n",
    "    reduce_test = pd.DataFrame(compiled_test)\n",
    "    categoricals = ['session_title']\n",
    "    return reduce_train, reduce_test, categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b58cdad5ae49d2b28c512031f8c3f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da61de35647479d911f82b5addf3466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get usefull dict with maping encode\n",
    "train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code = encode_title(train, test, train_labels)\n",
    "# tranform function to get the train and test set\n",
    "reduce_train, reduce_test, categoricals = get_train_and_test(train, test)\n",
    "# reduce_train.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_train.columns]\n",
    "# reduce_test.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_train.to_csv('data\\\\new\\\\reduce_train.csv',index=False)\n",
    "reduce_test.to_csv('data\\\\new\\\\reduce_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce_train = pd.read_csv('data/new/reduce_train.csv')\n",
    "# reduce_test = pd.read_csv('data/new/reduce_test.csv') \n",
    "# sample_submission=pd.read_csv('data/sample_submission.csv')\n",
    "# categoricals = ['session_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**去除无效特征，一个是accuracy_group其实是y值，installation_id不需要作为特征；其次是实际是只对有assessment的数据进行了转化，因此有很多独热编码的event_id和event_code都是0值，所以可以直接剔除**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901\n"
     ]
    }
   ],
   "source": [
    "features = reduce_train.loc[:,(reduce_train.sum(axis=0) != 0)].columns # delete useless columns\n",
    "features = [x for x in temp if x not in ['accuracy_group', 'installation_id']]\n",
    "\n",
    "print(len(features))\n",
    "#降维后只有901个特征量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对test集进行转化，本质上是test集的各个程序的运行session明显比train集少，所以这里是乘以了一个系数来尽量和train集相符合；\n",
    "但如果明显大于10或小于0.1，则不进行系数优化（这里的系数是可以进一步优化的）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stract_hists(feature, train=reduce_train, test=reduce_test, adjust=False, plot=False):\n",
    "    n_bins = 10\n",
    "    train_data = train[feature]\n",
    "    test_data = test[feature]\n",
    "    if adjust:\n",
    "        test_data *= train_data.mean() / test_data.mean()\n",
    "    perc_90 = np.percentile(train_data, 95)\n",
    "    train_data = np.clip(train_data, 0, perc_90)\n",
    "    test_data = np.clip(test_data, 0, perc_90)\n",
    "    train_hist = np.histogram(train_data, bins=n_bins)[0] / len(train_data)\n",
    "    test_hist = np.histogram(test_data, bins=n_bins)[0] / len(test_data)\n",
    "    msre = mean_squared_error(train_hist, test_hist)\n",
    "    if plot:\n",
    "        print(msre)\n",
    "        plt.bar(range(n_bins), train_hist, color='blue', alpha=0.5)\n",
    "        plt.bar(range(n_bins), test_hist, color='red', alpha=0.5)\n",
    "        plt.show()\n",
    "    return msre\n",
    "# stract_hists('Magma Peak - Level 1_2000', adjust=False, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_Cart Balancer (Assessment) -0.04020325710970116 -0.47065833333333346 0.006732930476733109\n",
      "ab4ec3a4 0.0009044657998869418 0.0\n",
      "2ec694de 0.008988128886376484 0.0\n",
      "003cd2ee 0.0 0.0\n",
      "0ce40006 0.0008479366873940079 0.0\n",
      "e4d32835 0.0013001695873374789 0.0\n",
      "eb2c19cd 0.17382702091577162 0.008 0.0\n",
      "17ca3959 0.0 0.0\n",
      "29a42aea 0.004070096099491238 0.0\n",
      "13f56524 0.04392312040700961 0.0\n",
      "ecc6157f 0.007292255511588468 0.0\n",
      "6aeafed4 0.14703222159412097 0.008 0.0\n",
      "a8cc6fec 0.0 0.0\n",
      "4074bac2 0.0 0.0\n",
      "5dc079d8 0.0 0.0\n",
      "611485c5 0.0013566986998304127 0.0\n",
      "7fd1ac25 0.01978518937252685 0.0\n",
      "1b54d27f 0.0007348784624081402 0.0\n",
      "01ca3a3c 0.0004522328999434709 0.0\n",
      "bfc77bd6 0.012832108535895986 0.0\n",
      "dcb1663e 0.0 0.0\n",
      "119b5b02 0.0002826455624646693 0.0\n",
      "Egg Dropper (Activity)_4080 0.01978518937252685 0.0\n",
      "Bubble Bath_4090 0.14703222159412097 0.008 0.0\n",
      "Leaf Leader_4080 0.0004522328999434709 0.0\n",
      "Bottle Filler (Activity)_2010 0.0 0.0\n",
      "Crystals Rule_2010 0.0 0.0\n",
      "Fireworks (Activity)_4080 0.0013566986998304127 0.0\n",
      "Air Show_4080 0.0 0.0\n",
      "Bubble Bath_4080 0.004070096099491238 0.0\n",
      "Bug Measurer (Activity)_4080 0.008988128886376484 0.0\n",
      "Scrub-A-Dub_4080 0.0 0.0\n",
      "Watering Hole (Activity)_2010 0.0007348784624081402 0.0\n",
      "Mushroom Sorter (Assessment)_4080 0.04392312040700961 0.0\n",
      "Pan Balance_4080 0.0013001695873374789 0.0\n",
      "Dino Dive_4080 0.0002826455624646693 0.0\n",
      "Sandcastle Builder (Activity)_2010 0.0 0.0\n",
      "Pan Balance_2010 0.0 0.0\n",
      "Happy Camel_4080 0.0008479366873940079 0.0\n",
      "Dino Drink_4080 0.0009044657998869418 0.0\n",
      "Mushroom Sorter (Assessment)_4090 0.17382702091577162 0.008 0.0\n",
      "Cart Balancer (Assessment)_4080 0.007292255511588468 0.0\n",
      "Chest Sorter (Assessment)_4080 0.012832108535895986 0.0\n"
     ]
    }
   ],
   "source": [
    "to_exclude = [] \n",
    "ajusted_test = reduce_test.copy()\n",
    "for feature in ajusted_test.columns:\n",
    "    if feature not in ['accuracy_group', 'installation_id', 'accuracy_group', 'session_title']:\n",
    "        data = reduce_train[feature]\n",
    "        train_mean = data.mean()\n",
    "        data = ajusted_test[feature] \n",
    "        test_mean = data.mean()\n",
    "        try:\n",
    "            error = stract_hists(feature, adjust=True)\n",
    "            ajust_factor = train_mean / test_mean\n",
    "            if ajust_factor > 10 or ajust_factor < 0.1:# or error > 0.01:\n",
    "                to_exclude.append(feature)\n",
    "                print(feature, train_mean, test_mean, error)\n",
    "            else:\n",
    "                ajusted_test[feature] *= ajust_factor\n",
    "        except:\n",
    "            to_exclude.append(feature)\n",
    "            print(feature, train_mean, test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_qwk_lgb_regr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fast cappa eval function for lgb.\n",
    "    \"\"\"\n",
    "    dist = Counter(reduce_train['accuracy_group'])\n",
    "    for k in dist:\n",
    "        dist[k] /= len(reduce_train)\n",
    "    reduce_train['accuracy_group'].hist()\n",
    "    \n",
    "    acum = 0\n",
    "    bound = {}\n",
    "    for i in range(3):\n",
    "        acum += dist[i]\n",
    "        bound[i] = np.percentile(y_pred, acum * 100)\n",
    "\n",
    "    def classify(x):\n",
    "        if x <= bound[0]:\n",
    "            return 0\n",
    "        elif x <= bound[1]:\n",
    "            return 1\n",
    "        elif x <= bound[2]:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "    y_pred = np.array(list(map(classify, y_pred))).reshape(y_true.shape)\n",
    "\n",
    "    return 'cappa', cohen_kappa_score(y_true, y_pred, weights='quadratic'), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base_Model(object):\n",
    "    \n",
    "    def __init__(self, train_df, test_df, features, categoricals=[], n_splits=5, verbose=True):\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.features = features\n",
    "        self.n_splits = n_splits\n",
    "        self.categoricals = categoricals\n",
    "        self.target = 'accuracy_group'\n",
    "        self.cv = self.get_cv()\n",
    "        self.verbose = verbose\n",
    "        self.params = self.get_params()\n",
    "        self.y_pred, self.score, self.model = self.fit()\n",
    "        \n",
    "    def train_model(self, train_set, val_set):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def get_cv(self):\n",
    "        cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
    "        return cv.split(self.train_df, self.train_df[self.target])\n",
    "    \n",
    "    def get_params(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_x(self, x):\n",
    "        return x\n",
    "        \n",
    "    def fit(self):\n",
    "        oof_pred = np.zeros((len(reduce_train), ))\n",
    "        y_pred = np.zeros((len(reduce_test), ))\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv):\n",
    "            x_train, x_val = self.train_df[self.features].iloc[train_idx], self.train_df[self.features].iloc[val_idx]\n",
    "            y_train, y_val = self.train_df[self.target][train_idx], self.train_df[self.target][val_idx]\n",
    "            train_set, val_set = self.convert_dataset(x_train, y_train, x_val, y_val)\n",
    "            model = self.train_model(train_set, val_set)\n",
    "            conv_x_val = self.convert_x(x_val)\n",
    "            oof_pred[val_idx] = model.predict(conv_x_val).reshape(oof_pred[val_idx].shape)\n",
    "            x_test = self.convert_x(self.test_df[self.features])\n",
    "            y_pred += model.predict(x_test).reshape(y_pred.shape) / self.n_splits\n",
    "            print('Partial score of fold {} is: {}'.format(fold, eval_qwk_lgb_regr(y_val, oof_pred[val_idx])[1]))\n",
    "        _, loss_score, _ = eval_qwk_lgb_regr(self.train_df[self.target], oof_pred)\n",
    "        if self.verbose:\n",
    "            print('Our oof cohen kappa score is: ', loss_score)\n",
    "        return y_pred, loss_score, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lgb_Model(Base_Model):\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        return lgb.train(self.params, train_set, valid_sets=[train_set, val_set], verbose_eval=verbosity)\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = lgb.Dataset(x_train, y_train, categorical_feature=self.categoricals)\n",
    "        val_set = lgb.Dataset(x_val, y_val, categorical_feature=self.categoricals)\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = {'n_estimators':5000,\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'regression',\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample': 0.75,\n",
    "                    'subsample_freq': 1,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'feature_fraction': 0.9,\n",
    "                    'max_depth': 15,\n",
    "                    'lambda_l1': 1,  \n",
    "                    'lambda_l2': 1,\n",
    "                    'early_stopping_rounds': 100\n",
    "                    }\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xgb_Model(Base_Model):\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        return xgb.train(self.params, train_set, \n",
    "                         num_boost_round=5000, evals=[(train_set, 'train'), (val_set, 'val')], \n",
    "                         verbose_eval=verbosity, early_stopping_rounds=100)\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = xgb.DMatrix(x_train, y_train)\n",
    "        val_set = xgb.DMatrix(x_val, y_val)\n",
    "        return train_set, val_set\n",
    "    \n",
    "    def convert_x(self, x):\n",
    "        return xgb.DMatrix(x)\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = {'colsample_bytree': 0.8,                 \n",
    "            'learning_rate': 0.01,\n",
    "            'max_depth': 10,\n",
    "            'subsample': 1,\n",
    "            'objective':'reg:squarederror',\n",
    "            #'eval_metric':'rmse',\n",
    "            'min_child_weight':3,\n",
    "            'gamma':0.25,\n",
    "            'n_estimators':5000}\n",
    "\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import gc\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
